# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14Dtd53TB_WP592z9CFlV6iaAVPVGU48R
"""

# Re-run this cell and follow the interactive prompts to authenticate
from google.colab import drive
drive.mount('/content/drive')


import streamlit as st
from core import load_arxiv_data, prepare_corpus, get_embeddings, search

# File path to your dataset
JSON_PATH = '/content/drive/MyDrive/arxiv-metadata-oai-snapshot.json'

# Load and cache data
@st.cache_data(show_spinner=False)
def get_data():
    data = load_arxiv_data(JSON_PATH, max_entries=10000)
    corpus = prepare_corpus(data)
    return data, corpus

# Load and cache embeddings
@st.cache_resource(show_spinner=False)
def get_cached_embeddings(corpus):
    return get_embeddings(corpus)

# Streamlit App
st.title("ðŸ“š AI Academic Paper Search")
st.write("Enter a research query to find relevant arXiv papers.")

# Get data and embeddings
data, corpus = get_data()
embeddings, model = get_cached_embeddings(corpus)

# User query input
query = st.text_input("Enter your search query:")

if st.button("Search"):
    if query.strip() == "":
        st.warning("Please enter a valid query.")
    else:
        results = search(query, embeddings, model, data, top_k=5)
        for paper in results:
            st.markdown(f"### {paper['title']}")
            st.markdown(f"**Authors:** {paper['authors']}")
            st.markdown(f"**Abstract:** {paper['abstract'][:500]}...")
            st.markdown(f"**Categories:** `{paper['categories']}`")
            st.markdown(f"**arXiv ID:** {paper['id']}")
            st.markdown("---")
